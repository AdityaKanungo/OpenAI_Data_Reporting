import os
import openai
import pandas as pd
import json

def load_data_dictionary(excel_path: str) -> pd.DataFrame:
    """
    Loads the data dictionary from an Excel file into a pandas DataFrame.
    """
    return pd.read_excel(excel_path)

def load_rules_txt(rules_txt_path: str) -> str:
    """
    Loads the entire domain rules from a text file.
    """
    with open(rules_txt_path, 'r', encoding='utf-8') as f:
        return f.read()

def load_abbreviations(abbreviations_csv_path: str) -> dict:
    """
    Loads abbreviations from a CSV file as a Python dictionary.
    Expects columns: [word, abbreviation].
    Returns a dict of {word: abbreviation}.
    """
    df_abbr = pd.read_csv(abbreviations_csv_path)
    # Convert to { "Employee" : "EMP", "Number" : "NUM", ... }
    abbr_dict = df_abbr.set_index("word")["abbreviation"].to_dict()
    return abbr_dict

def generate_prompt_from_txt_rules(row_data: dict, rules_text: str, abbr_dict: dict) -> str:
    """
    Incorporates text-based domain rules, plus all abbreviations, into the prompt.
    """
    # Build one big list of all abbreviations
    abbreviations_text = "\n".join([
        f"{word} -> {abbr}" for word, abbr in abbr_dict.items()
    ])
    
    prompt = f"""
You are a data dictionary validation assistant. 
Apply the following domain rules strictly:
---
{rules_text}
---

Here is a list of all known abbreviations in this domain:
{abbreviations_text}

Please review the following data dictionary row:

ACD: {row_data.get('ACD', '')}
Schema: {row_data.get('Schema', '')}
Table Name: {row_data.get('Table Name', '')}
Column Name: {row_data.get('Column Name', '')}
Data Type: {row_data.get('Data Type', '')}
Precision: {row_data.get('Precision', '')}
Scale: {row_data.get('Scale', '')}
Nullable?: {row_data.get('Nullable ?', '')}
Default Value: {row_data.get('Default value', '')}
Description/Business Rules: {row_data.get('Description/Business Rules', '')}
Is PK?: {row_data.get('Is PK (YES/NO)', '')}
Is FK?: {row_data.get('Is FK?(YES/NO)', '')}
Reference Table?: {row_data.get('Reference Table(YES/NO)', '')}

Task:
1) Identify any violations of the naming rules (e.g., length > 10, incorrect abbreviations, missing class words, etc.).
2) Suggest corrected naming if needed.
3) Indicate pass/fail and reason.

Return your response in JSON:
{{
    "compliance": "PASS" or "FAIL",
    "reasons": ["..."],
    "suggested_table_name": "...",
    "suggested_column_name": "...",
    "other_corrections": "...",
    "notes": "..."
}}
    """
    return prompt

def call_openai_api(prompt: str, model: str = "gpt-3.5-turbo") -> dict:
    """
    Calls the OpenAI ChatCompletion API with the given prompt.
    """
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            max_tokens=500
        )
        content = response['choices'][0]['message']['content']
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            # If JSON parsing fails, return raw response
            return {"raw_response": content}
    except Exception as e:
        return {"error": str(e)}

def validate_row(row: pd.Series, rules_text: str, abbr_dict: dict) -> dict:
    """
    Validates a single row by:
      1) Optionally do local checks for abbreviations.
      2) Generate a prompt that includes domain rules & full abbreviation dictionary.
      3) Call OpenAI with that prompt.
    """
    row_data = row.to_dict()
    table_name = row_data.get("Table Name", "")
    column_name = row_data.get("Column Name", "")

    # --- EXAMPLE: Local check for valid abbreviations before LLM ---
    # For demonstration, let's say each "word" in the table or column name must be in abbr_dict.values()
    # or be an acceptable 'word' in abbr_dict.keys(). This is up to your naming standards:
    
    # Simple approach: check if table_name or column_name includes a known abbreviation
    # (This is just an example logic — adapt to your real naming conventions)
    invalid_abbr = []
    
    # Suppose table name is "EMP_NUM" => words: ["EMP", "NUM"]
    # We check if each chunk is in abbr_dict.values() (the set of known abbreviations).
    # Or if we store reversed keys in abbr_dict, you’d adapt accordingly.
    for chunk in table_name.split("_"):
        if chunk and (chunk not in abbr_dict.values()):
            invalid_abbr.append(chunk)
            
    for chunk in column_name.split("_"):
        if chunk and (chunk not in abbr_dict.values()):
            invalid_abbr.append(chunk)

    # You can store the local check results in row_data so the LLM can see it if desired
    row_data["Local Abbreviation Check"] = (
        f"Invalid abbreviations found: {invalid_abbr}" if invalid_abbr else "All abbreviations OK"
    )

    # Now generate the prompt with everything included
    prompt = generate_prompt_from_txt_rules(row_data, rules_text, abbr_dict)
    
    # Call the OpenAI API
    gpt_result = call_openai_api(prompt, model="gpt-3.5-turbo")

    # If the response does not contain the keys we want, fill in placeholders
    if "compliance" not in gpt_result:
        gpt_result["compliance"] = "UNKNOWN"
        gpt_result["notes"] = gpt_result.get("raw_response", "")

    return gpt_result

def process_data_dictionary(df: pd.DataFrame, rules_text: str, abbr_dict: dict) -> pd.DataFrame:
    """
    Processes the data dictionary row-by-row, validating each row individually.
    """
    results_list = []
    for idx, row in df.iterrows():
        validation_result = validate_row(row, rules_text, abbr_dict)
        
        # Combine original row info + GPT output
        results_list.append({
            "RowID": idx,
            "Original_TableName": row.get("Table Name", ""),
            "Original_ColumnName": row.get("Column Name", ""),
            "Compliance": validation_result.get("compliance", "UNKNOWN"),
            "Reasons": validation_result.get("reasons", []),
            "Suggested_TableName": validation_result.get("suggested_table_name", ""),
            "Suggested_ColumnName": validation_result.get("suggested_column_name", ""),
            "Other_Corrections": validation_result.get("other_corrections", ""),
            "Notes": validation_result.get("notes", "")
        })
    
    return pd.DataFrame(results_list)

def main():
    # Load OpenAI API key from environment or fallback
    openai.api_key = os.getenv("OPENAI_API_KEY", "YOUR_API_KEY")

    excel_path = "data/data_dictionary.xlsx"
    rules_txt_path = "data/domain_rules.txt"
    abbreviations_csv_path = "data/abbreviations.csv"

    # Load Data
    df_dict = load_data_dictionary(excel_path)
    rules_text = load_rules_txt(rules_txt_path)
    abbr_dict = load_abbreviations(abbreviations_csv_path)

    # Process validation row by row
    result_df = process_data_dictionary(df_dict, rules_text, abbr_dict)

    # Export to Excel
    result_df.to_excel("validation_report.xlsx", index=False)
    print("Validation complete. Results saved to 'validation_report.xlsx'")

if __name__ == "__main__":
    main()
