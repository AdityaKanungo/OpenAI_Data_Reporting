import streamlit as st
import pandas as pd
import json
import openai
from typing import Dict, List, Any
from itertools import combinations
import io

# ==============================
# 1. DATA LOADING FUNCTIONS
# ==============================

def load_data_dictionary(uploaded_file) -> pd.DataFrame:
    return pd.read_excel(uploaded_file)

def load_rules_txt(uploaded_file) -> str:
    return uploaded_file.read().decode("utf-8", errors="ignore")

def load_abbreviations(uploaded_file) -> Dict[str, str]:
    df_abbr = pd.read_csv(uploaded_file, encoding="utf-8")
    df_abbr.columns = df_abbr.columns.str.strip()
    df_abbr = df_abbr.applymap(lambda x: x.strip().upper() if isinstance(x, str) else x)
    return df_abbr.set_index("NAME")['ABBR'].to_dict()

def load_class_words(uploaded_file) -> List[str]:
    df_class = pd.read_csv(uploaded_file, encoding="utf-8")
    return df_class['CLASS WORDS'].str.strip().str.upper().tolist()

def check_column_parts(column_name: str, abbreviations: Dict[str, str], english_name: str, class_words: List[str]) -> List[str]:
    column_parts = column_name.split('_')
    english_words = english_name.split()
    possible_combinations = set()
    missing_words = []
    
    for length in range(1, len(english_words) + 1):
        for subset in combinations(english_words, length):
            phrase = " ".join(subset)
            if phrase in abbreviations:
                possible_combinations.add(abbreviations[phrase])
    
    possible_combinations.update([abbreviations.get(word, word) for word in english_words])
    possible_combinations.update(class_words)
    
    for part in column_parts:
        if part not in possible_combinations:
            missing_words.append(part)
    
    return missing_words

def call_openai_suggestion(table_name: str, column_name: str, failure_reasons: str, rules_text: str) -> Dict[str, str]:
    prompt = f"""
    You are an expert in database table and column naming conventions.
    Based on the following validation failure reasons and naming rules, suggest a corrected table and column name.
    
    Table Name: {table_name}
    Column Name: {column_name}
    
    Failure Reasons:
    {failure_reasons}
    
    Naming Rules:
    {rules_text}
    
    Format the response as JSON:
    {{
      "Suggested Table Name": "{table_name}",
      "Suggested Column Name": "{column_name}",
      "Additional Notes": "Provide any relevant notes."
    }}
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return json.loads(response["choices"][0]["message"]["content"])
    except Exception as e:
        return {"Suggested Table Name": table_name, "Suggested Column Name": column_name, "Additional Notes": "N/A", "Error": str(e)}
def validate_data_dictionary(df: pd.DataFrame, class_words: List[str], abbreviations: Dict[str, str], rules_text: str) -> pd.DataFrame:
    results = []
    for _, row in df.iterrows():
        table_name = str(row.get('Table Name', '')).strip().upper()
        column_name = str(row.get('Column Name', '')).strip().upper()
        english_name = str(row.get('English Name', '')).strip()
        
        # Ensure English Name is formatted properly (Title Case)
        formatted_english_name = " ".join(word.capitalize() for word in english_name.split())

        table_valid = table_name.startswith('T') and (table_name.endswith('FACT') or table_name.endswith('DIM'))
        missing_parts = check_column_parts(column_name, abbreviations, english_name.upper(), class_words)
        
        failure_reasons = []
        if not table_valid:
            failure_reasons.append("Table name must start with 'T' and end with 'FACT' or 'DIM'.")
        if missing_parts:
            failure_reasons.append(f"Column name is missing or incorrect for: {', '.join(missing_parts)}")
        
        validation_status = "PASS" if not failure_reasons else "FAIL"
        
        suggested_names = {"Suggested Table Name": "", "Suggested Column Name": "", "Additional Notes": "N/A"}
        if validation_status == "FAIL":
            suggested_names = call_openai_suggestion(table_name, column_name, "; ".join(failure_reasons), rules_text)
        
        results.append({
            "Table Name": table_name,
            "Column Name": column_name,
            "English Name": formatted_english_name,  # Apply the title case transformation here
            "Validation Status": validation_status,
            "Notes": "Valid" if validation_status == "PASS" else "; ".join(failure_reasons),
            "Suggested Table Name": suggested_names.get("Suggested Table Name", ""),
            "Suggested Column Name": suggested_names.get("Suggested Column Name", ""),
            "Additional Notes": suggested_names.get("Additional Notes", "N/A"),
            "Error": suggested_names.get("Error", "None")
        })
    
    return pd.DataFrame(results)


def main():
    st.set_page_config(page_title="Data Dictionary Validator", layout="wide")
    st.title("üìä Data Dictionary Validator")
    
    openai.api_key = st.sidebar.text_input("Enter OpenAI API Key", type="password")
    
    uploaded_dict = st.sidebar.file_uploader("Upload Data Dictionary (Excel)", type=["xlsx"])
    uploaded_rules = st.sidebar.file_uploader("Upload Domain Rules (Text)", type=["txt"])
    uploaded_abbr = st.sidebar.file_uploader("Upload Abbreviations (CSV)", type=["csv"])
    uploaded_class_words = st.sidebar.file_uploader("Upload Class Words (CSV)", type=["csv"])
    
    if uploaded_dict and uploaded_rules and uploaded_abbr and uploaded_class_words and openai.api_key:
        df_dict = load_data_dictionary(uploaded_dict)
        rules_text = load_rules_txt(uploaded_rules)
        abbreviations = load_abbreviations(uploaded_abbr)
        class_words = load_class_words(uploaded_class_words)

        if st.button("üîç Validate & Suggest Corrections"):
            with st.spinner("Processing validation..."):
                st.session_state["results_df"] = validate_data_dictionary(df_dict, class_words, abbreviations, rules_text)
        
    if "results_df" in st.session_state:
        df_results = st.session_state["results_df"]
        
        if not df_results.empty:
            st.subheader("Validation Results")
            st.dataframe(df_results)

            # Extract only failed rows
            failed_rows_df = df_results[df_results['Validation Status'] == "FAIL"]
            
            if not failed_rows_df.empty:
                st.subheader("üö® Failed Rows")
                
                # Create a dropdown to select a specific failed row based on Column Name
                selected_failed_row = st.selectbox(
                    "Select a Failed Column to View Details",
                    failed_rows_df["Column Name"].tolist(),
                    index=0
                )

                # Display the selected failed row details
                selected_row_data = failed_rows_df[failed_rows_df["Column Name"] == selected_failed_row].to_dict(orient='records')[0]
                st.json(selected_row_data)  # Display details in JSON format for better readability

            # Convert DataFrame to Excel
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                df_results.to_excel(writer, sheet_name="Validation Report", index=False)
            
            excel_data = output.getvalue()
            
            st.download_button(
                label="üì• Download Validation Report (Excel)",
                data=excel_data,
                file_name="Validation_Report.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )


if __name__ == "__main__":
    main()
