import tiktoken
import os
import re
import json
import time
from openai import AzureOpenAI

# Updated user prompt template with dynamic flow details
user_prompt_template = """
You will analyze multiple COBOL batch programs provided by the user.
Identify all variables defined in the WORKING-STORAGE SECTION and LINKAGE SECTION,
including their data types, initial values, and any descriptions or comments.
Then trace how each variable is used, modified, or transformed throughout the PROCEDURE DIVISION.

Here's the flow details for the batch programs:
{flow_details}

Please identify all the variables involved, their transformations, and how data flows from one program to the next.
Capture all the necessary information to create a detailed understanding of each program's role in the batch processing flow.

Provide the details in the following JSON format:

{
  "program_name": "name_of_the_program",
  "start_sequence": "start_sequence_identifier",
  "end_sequence": "end_sequence_identifier",
  "interim_files": ["list_of_interim_files"],
  "input_sources": ["input_files_if_any"],
  "variables": [
    {
      "variable_name": "string",
      "data_type": "string",
      "initial_value": "string or null",
      "description": "string or null"
    }
  ],
  "transformations": [
    {
      "variable_name": "string",
      "line_number": "integer",
      "operation": "description of the transformation",
      "logic": "explanation of the logic applied",
      "affected_by": ["list of other variables influencing this transformation"]
    }
  ],
  "output_destinations": ["list_of_output_files"]
}
"""

system_prompt = """
You are an expert COBOL code analyzer.
Your task is to analyze each COBOL program provided by the user.
You need to identify all variables defined in the WORKING-STORAGE SECTION and LINKAGE SECTION,
including their data types, initial values, and any relevant descriptions or comments.
Furthermore, you must track how each of these variables is used, modified, or transformed throughout the PROCEDURE DIVISION.
Ensure you maintain the flow of data from one program to the next, retaining the linkage between programs based on their input and output.
Your goal is to provide a comprehensive JSON output that captures each variable's complete lifecycle,
from its initial definition to its final state, including any transformations, calculations, and dependencies, across all programs.
"""

# Helper functions
def num_tokens_from_string(string: str, encoding_name: str) -> int:
    encoding = tiktoken.get_encoding(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens

def remove_comments(cobol_code):
    inline_comment_pattern = r'^.{6}[*$]'
    cobol_code = re.sub(inline_comment_pattern, '', cobol_code, flags=re.MULTILINE)
    return cobol_code

def read_file(file: str) -> str:
    with open(file, 'r', encoding='utf-8') as cobol_file:
        contents = cobol_file.read()
    return contents

def analyze_cobol_code(contents, user_prompt, system_prompt):
    user_prompt = user_prompt + contents
    if num_tokens_from_string(user_prompt, 'cl100k_base') < 300000:
        response = client.chat.completions.create(
            model = deployment_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2
        )
        return response.choices[0].message.content
    else:
        print(f"File is too large at {num_tokens_from_string(user_prompt, 'cl100k_base')} tokens")
        return None

def process_batch_files(batch_directory, output_directory, flow_details):
    start_time = time.time()
    os.chdir(batch_directory)
    
    # Incorporate flow details into the user prompt
    user_prompt_with_flow = user_prompt_template.format(flow_details=flow_details)

    # Process each COBOL program
    batch_files = [f for f in os.listdir(batch_directory) if f.endswith('.txt')]
    
    consolidated_results = []

    for batch_file in batch_files:
        print(f"Processing file: {batch_file}")
        
        # Read and clean the COBOL code
        file_contents = read_file(batch_file)
        cobol_code = remove_comments(file_contents)
        
        # Analyze the code with LLM using the updated user prompt
        analysis_result = analyze_cobol_code(cobol_code, user_prompt_with_flow, system_prompt)

        if analysis_result:
            try:
                # Parse the result as JSON and add to consolidated results
                analysis_json = json.loads(analysis_result)
                consolidated_results.append(analysis_json)
                
                # Save individual program's JSON output
                json_filename = os.path.join(output_directory, f"{batch_file.split('.')[0]}_analysis.json")
                with open(json_filename, "w", encoding='utf-8') as json_file:
                    json.dump(analysis_json, json_file, indent=4)
                print(f"Analysis successfully saved to {json_filename}")
                
            except json.JSONDecodeError:
                print(f"Error: The response from OpenAI was not in the expected JSON format for {batch_file}")

    # Save the consolidated JSON output for all programs
    consolidated_filename = os.path.join(output_directory, "consolidated_analysis.json")
    with open(consolidated_filename, "w", encoding='utf-8') as consolidated_file:
        json.dump(consolidated_results, consolidated_file, indent=4)
    
    print(f"Consolidated JSON output saved to {consolidated_filename}")
    print(f"Processing completed in {time.time() - start_time} seconds.")

# Define your input and output directories and flow details
batch_directory = r"path\to\batch_files"  # Update this path
output_directory = r"path\to\output_files"  # Update this path
flow_details = """
CIT23MS (Starting point) -> CIT25MS & CIT28MS
CIT25MS & CIT28MS -> CIT22MS
CIT22MS -> TNF23MS -> TNF22MS (Final_output)
"""

# Run the processing function
if __name__ == "__main__":
    process_batch_files(batch_directory, output_directory, flow_details)
